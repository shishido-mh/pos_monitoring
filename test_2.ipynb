{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## app.py\n",
    "### Description\n",
    "The app.py script is a Flask application designed for anomaly detection and monitoring in transaction data. It incorporates a machine learning model (Isolation Forest) to predict anomalies and utilizes a SQLite database to store transaction records. The script exposes several endpoints for receiving transactions, retrieving transaction data, and checking alerts based on predefined thresholds.\n",
    "### Endpoints\n",
    "#### 1. /\n",
    "Method: GET\n",
    "\n",
    "Description: Renders the index page.\n",
    "#### 2. /receive_transaction\n",
    "Method: POST\n",
    "\n",
    "Description: Receives transaction data, predicts anomalies, stores transaction records, and returns a JSON response with anomaly test results.\n",
    "##### Request Payload\n",
    "```json\n",
    "{\n",
    "    \"time\": \"hh:mm\",\n",
    "    \"hour\": 12,\n",
    "    \"minute\": 30,\n",
    "    \"approved\": 100,\n",
    "    \"backend_reversed\": 0,\n",
    "    \"denied\": 5,\n",
    "    \"failed\": 2,\n",
    "    \"processing\": 3,\n",
    "    \"refunded\": 10,\n",
    "    \"reversed\": 1,\n",
    "    \"total\": 120,\n",
    "    \"success_rate\": 0.85,\n",
    "    \"denial_rate\": 0.04,\n",
    "    \"reversal_rate\": 0.01,\n",
    "    \"failure_rate\": 0.02\n",
    "}\n",
    "```\n",
    "##### Response\n",
    "```json\n",
    "{\n",
    "    \"time\": \"hh:mm\",\n",
    "    \"score_test\": [\n",
    "        {\n",
    "            \"is_anomalous\": \"true\",\n",
    "            \"value\": -0.123,\n",
    "            \"description\": \"model score\"\n",
    "        }\n",
    "    ],\n",
    "    \"reversal_test\": [\n",
    "        {\n",
    "            \"is_anomalous\": \"false\",\n",
    "            \"value\": 0.01,\n",
    "            \"description\": \"reversal rate\"\n",
    "        }\n",
    "    ],\n",
    "    ...\n",
    "}\n",
    "\n",
    "```\n",
    "#### 3. /api/transactions\n",
    "Method: GET\n",
    "\n",
    "Description: Retrieves all transactions from the database.\n",
    "##### Response\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"time\": \"hh:mm\",\n",
    "        \"hour\": 12,\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "### Database\n",
    "The application uses an SQLite database named transactions.db to store transaction records. The Transaction table schema includes fields such as time, hour, minute, approved, denied, failed, reversed, total, success_rate, denial_rate, reversal_rate, failure_rate, and z_score.\n",
    "### Email alerts\n",
    "The application implements an example function send_email_alert to send email alerts when certain triggers are met. Replace this function with your actual email alert implementation using a suitable library like Flask-Mail or smtplib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monitoring_model.py\n",
    "### Overview\n",
    "This script demonstrates the process of training an Isolation Forest model using transaction data and saving the trained model to a file using Joblib. It involves data preprocessing, model creation, fitting the model with training data, and saving the model for future use.\n",
    "### Script Workflow\n",
    "#### Import Dependencies\n",
    "\n",
    "- pandas: For data manipulation.\n",
    "- Pivot (custom module): For pivoting data (not included in this script).\n",
    "- IsolationForest from sklearn.ensemble: To create the Isolation Forest model.\n",
    "- dump from joblib: For saving the model.\n",
    "#### Load Data\n",
    "\n",
    "Reads transaction data from a CSV file hosted on GitHub (transactions_1.csv).\n",
    "#### Data Preprocessing\n",
    "\n",
    "Uses the custom pivot_df function from the Pivot module to pivot the DataFrame (X) and create a training DataFrame (X_train).\n",
    "#### Feature Selection\n",
    "\n",
    "Selects relevant columns (cols) from the training DataFrame to train the model. These columns include features such as approved, backend_reversed, denied, failed, processing, reversed, total, success_rate, reversal_rate, denial_rate, failure_rate, hour, and minute.\n",
    "#### Model Creation\n",
    "\n",
    "Initializes an Isolation Forest model with a random state of 42.\n",
    "#### Model Training\n",
    "\n",
    "Fits the Isolation Forest model with the selected features (cols) from the training DataFrame (X_train).\n",
    "#### Save Model\n",
    "\n",
    "Saves the trained Isolation Forest model to a file named isolation_forest_model.joblib using the dump function from Joblib.\n",
    "\n",
    "#### Print Confirmation:\n",
    "\n",
    "Outputs a message indicating that the model has been saved successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pivoter.py\n",
    "\n",
    "### Overview\n",
    "\n",
    "The `pivoter.py` module contains a class `Pivot` with a static method `pivot_df` that performs data pivoting and calculates additional metrics based on transaction data. It is designed to transform a DataFrame by pivoting it based on specific columns and computing rates such as success rate, denial rate, reversal rate, and failure rate.\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "- **pandas**: Required for data manipulation and handling.\n",
    "\n",
    "### Class: Pivot\n",
    "\n",
    "#### Method: `pivot_df`\n",
    "\n",
    "- **Description:** Performs data pivoting and computes additional metrics for transaction data.\n",
    "- **Parameters:**\n",
    "  - `df` (DataFrame): The input DataFrame containing transaction data.\n",
    "- **Returns:**\n",
    "  - `pivoted` (DataFrame): The pivoted DataFrame with calculated rates and additional columns.\n",
    "\n",
    "#### Data Pivoting\n",
    "\n",
    "The `pivot_df` method pivots the input DataFrame (`df`) based on the following columns:\n",
    "\n",
    "```python\n",
    "index='time', columns='status', values='f0_', fill_value=0\n",
    "```\n",
    "\n",
    "### Calculated Metrics\n",
    "The pivoted DataFrame (pivoted) includes the following calculated metrics:\n",
    "\n",
    "- total: Sum of values across all status columns.\n",
    "- success_rate: Ratio of 'approved' transactions to total transactions.\n",
    "- denial_rate: Ratio of 'denied' transactions to total transactions.\n",
    "- reversal_rate: Ratio of 'reversed' and 'backend_reversed' transactions to total transactions.\n",
    "- failure_rate: Ratio of 'failed' transactions to total transactions.\n",
    "\n",
    "### Additional Processing\n",
    "The pivoted DataFrame undergoes additional processing steps:\n",
    "\n",
    "1. Resetting the index and creating new columns for 'hour' and 'minute' based on the 'time' column.\n",
    "2. Filling any NaN values in the DataFrame with 0.\n",
    "### Usage\n",
    "Import the Pivot class from pivoter module:\n",
    "```python\n",
    "from pivoter import Pivot\n",
    "```\n",
    "Use the pivot_df method to pivot and process transaction data:\n",
    "```python\n",
    "pivoted_df = Pivot.pivot_df(input_df)\n",
    "```\n",
    "Use the processed DataFrame (pivoted_df) for further analysis or modeling.\n",
    "\n",
    "### Example\n",
    "```python\n",
    "import pandas as pd\n",
    "from pivoter import Pivot\n",
    "\n",
    "# Load data into DataFrame (df)\n",
    "\n",
    "# Pivot and process the DataFrame\n",
    "pivoted_df = Pivot.pivot_df(df)\n",
    "\n",
    "# Use the processed DataFrame for further analysis or modeling\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulator.py\n",
    "### Overview\n",
    "\n",
    "The `simulator.py` script simulates a scenario where POS (Point of Sale) data is read from a CSV file, pivoted using a custom library/module (`pivoter`), and sent to an API endpoint for processing. It uses pandas for data handling, requests for making API calls, and time for adding delays between API requests.\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "- pandas: For data manipulation and handling.\n",
    "- requests: For making HTTP requests to the API.\n",
    "- pivoter: A custom library/module (assumed to exist) for data pivoting.\n",
    "\n",
    "### Script Workflow\n",
    "1. Import Dependencies:\n",
    "\n",
    "- pandas: For data manipulation.\n",
    "- requests: For making HTTP requests.\n",
    "- Pivot (custom module): For pivoting data (assumed to exist).\n",
    "\n",
    "2. Read POS Data:\n",
    "\n",
    "Reads POS transaction data from a CSV file (transactions_2.csv) hosted online.\n",
    "\n",
    "3. API Configuration:\n",
    "\n",
    "Defines the API URL (url) where the transaction data will be sent (http://127.0.0.1:5000/receive_transaction).\n",
    "\n",
    "4. Data Pivoting:\n",
    "\n",
    "Uses the pivot_df method from the Pivot module to pivot the POS transaction data.\n",
    "\n",
    "5. API Requests:\n",
    "\n",
    "- Iterates over each row in the pivoted DataFrame (X_pivoted).\n",
    "- Converts each row to a dictionary (row_data).\n",
    "- Sends an HTTP POST request to the API endpoint (url) with the JSON data (row_data).\n",
    "\n",
    "6. Handling API Responses:\n",
    "\n",
    "- Checks if the API call was successful (status code 200).\n",
    "    - If successful, prints the response JSON.\n",
    "    - If unsuccessful, prints the status code and response text.\n",
    "- Adds a delay of 10 seconds between API requests using time.sleep(10).\n",
    "\n",
    "### Usage\n",
    "- Ensure that the CSV file (transactions_2.csv) containing POS transaction data is accessible and has the required format.\n",
    "- Make sure the API endpoint (http://127.0.0.1:5000/receive_transaction) is running and ready to receive data.\n",
    "- Run the script (simulator.py) using Python to simulate sending POS transaction data to the API.\n",
    "### Additional Notes\n",
    "Replace pivoter with the actual name of the custom library/module for data pivoting.\n",
    "Adjust the API URL (url) to point to the correct endpoint where you want to send the transaction data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
